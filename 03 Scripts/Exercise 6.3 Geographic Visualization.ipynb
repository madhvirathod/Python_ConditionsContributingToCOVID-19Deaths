{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3561000",
   "metadata": {},
   "source": [
    "# Geographic visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01f85dc",
   "metadata": {},
   "source": [
    "## This Script Contains the following"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18500cd9",
   "metadata": {},
   "source": [
    "### 1.Import data and libraries\n",
    "\n",
    "### 2. Data Wrangling\n",
    "\n",
    "### 3. Data Cleaning\n",
    "\n",
    "### 4. Plotting a Choropleth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8826769e",
   "metadata": {},
   "source": [
    "## 1. Import data and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e277f00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import os\n",
    "import folium\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89c2cc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This command propts matplotlib visuals to appear in the notebook \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859eb736",
   "metadata": {},
   "source": [
    "### Import the JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb73a5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import \".json\" file for the U.S. \n",
    "country_geo = r\"C:\\Users\\tjsra\\OneDrive\\Desktop\\CF data analyst\\Achievement 6\\02 Data\\Original Data\\us-states.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d45ff041",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(country_geo, 'r') as f:\n",
    "    geo_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07b1514",
   "metadata": {},
   "source": [
    "### Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fee4ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import_path = r\"C:\\Users\\tjsra\\OneDrive\\Desktop\\CF data analyst\\Achievement 6\\02 Data\\prepared data\\Conditions_Contributing_to_COVID-19_Deaths_Cleaned.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9af434ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(import_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3b30a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data As Of</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>End Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>State</th>\n",
       "      <th>Condition Group</th>\n",
       "      <th>Condition</th>\n",
       "      <th>ICD10_codes</th>\n",
       "      <th>Age Group</th>\n",
       "      <th>COVID-19 Deaths</th>\n",
       "      <th>Number of Mentions</th>\n",
       "      <th>Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-24</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Respiratory diseases</td>\n",
       "      <td>Influenza and pneumonia</td>\n",
       "      <td>J09-J18</td>\n",
       "      <td>0-24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-09-24</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Respiratory diseases</td>\n",
       "      <td>Influenza and pneumonia</td>\n",
       "      <td>J09-J18</td>\n",
       "      <td>0-24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-09-24</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Respiratory diseases</td>\n",
       "      <td>Influenza and pneumonia</td>\n",
       "      <td>J09-J18</td>\n",
       "      <td>0-24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-09-24</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>2020-04-30</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Respiratory diseases</td>\n",
       "      <td>Influenza and pneumonia</td>\n",
       "      <td>J09-J18</td>\n",
       "      <td>0-24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-09-24</td>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>2020-05-31</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Respiratory diseases</td>\n",
       "      <td>Influenza and pneumonia</td>\n",
       "      <td>J09-J18</td>\n",
       "      <td>0-24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data As Of  Start Date    End Date    Year  Month    State  \\\n",
       "0  2023-09-24  2020-01-01  2020-01-31  2020.0    1.0  Alabama   \n",
       "1  2023-09-24  2020-02-01  2020-02-29  2020.0    2.0  Alabama   \n",
       "2  2023-09-24  2020-03-01  2020-03-31  2020.0    3.0  Alabama   \n",
       "3  2023-09-24  2020-04-01  2020-04-30  2020.0    4.0  Alabama   \n",
       "4  2023-09-24  2020-05-01  2020-05-31  2020.0    5.0  Alabama   \n",
       "\n",
       "        Condition Group                Condition ICD10_codes Age Group  \\\n",
       "0  Respiratory diseases  Influenza and pneumonia     J09-J18      0-24   \n",
       "1  Respiratory diseases  Influenza and pneumonia     J09-J18      0-24   \n",
       "2  Respiratory diseases  Influenza and pneumonia     J09-J18      0-24   \n",
       "3  Respiratory diseases  Influenza and pneumonia     J09-J18      0-24   \n",
       "4  Respiratory diseases  Influenza and pneumonia     J09-J18      0-24   \n",
       "\n",
       "   COVID-19 Deaths  Number of Mentions Flag  \n",
       "0              0.0                 0.0  NaN  \n",
       "1              0.0                 0.0  NaN  \n",
       "2              0.0                 0.0  NaN  \n",
       "3              0.0                 0.0  NaN  \n",
       "4              0.0                 0.0  NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25d29be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(430560, 13)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfb6745",
   "metadata": {},
   "source": [
    "## 2. Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41a2510f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract state names from the dataset\n",
    "dataset_states = set(df['State'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49471f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract state names from the GeoJSON file\n",
    "geojson_states = set(feature['properties']['name'] for feature in geo_data['features'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38c210a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the state names\n",
    "missing_in_geojson = dataset_states - geojson_states\n",
    "missing_in_dataset = geojson_states - dataset_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6617c52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States in dataset but not in GeoJSON: {'District of Columbia', 'New York City'}\n",
      "States in GeoJSON but not in dataset: set()\n"
     ]
    }
   ],
   "source": [
    "print(f\"States in dataset but not in GeoJSON: {missing_in_geojson}\")\n",
    "print(f\"States in GeoJSON but not in dataset: {missing_in_dataset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012b8cf2",
   "metadata": {},
   "source": [
    "### To fix the discrepancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83c5e102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize state names in the dataset\n",
    "df['State'] = df['State'].str.strip().str.title()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6a207ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping dictionary for the missing states\n",
    "state_mapping = {\n",
    "    'District of Columbia': 'District of Columbia',\n",
    "    'New York City': 'New York'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bac14a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the mapping to the dataset\n",
    "df['State'] = df['State'].replace(state_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26f9738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-check for discrepancies\n",
    "dataset_states = set(df['State'].unique())\n",
    "geojson_states = set(feature['properties']['name'] for feature in geo_data['features'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "489c60e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_in_geojson = dataset_states - geojson_states\n",
    "missing_in_dataset = geojson_states - dataset_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "133733fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States in dataset but not in GeoJSON: {'District Of Columbia'}\n",
      "States in GeoJSON but not in dataset: set()\n"
     ]
    }
   ],
   "source": [
    "print(f\"States in dataset but not in GeoJSON: {missing_in_geojson}\")\n",
    "print(f\"States in GeoJSON but not in dataset: {missing_in_dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bec6fa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \"District Of Columbia\" from the dataset\n",
    "df = df[df['State'] != 'District Of Columbia']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99dc835e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-check for discrepancies\n",
    "dataset_states = set(df['State'].unique())\n",
    "missing_in_geojson = dataset_states - geojson_states\n",
    "missing_in_dataset = geojson_states - dataset_states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "634c785e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States in dataset but not in GeoJSON: set()\n",
      "States in GeoJSON but not in dataset: set()\n"
     ]
    }
   ],
   "source": [
    "print(f\"States in dataset but not in GeoJSON: {missing_in_geojson}\")\n",
    "print(f\"States in GeoJSON but not in dataset: {missing_in_dataset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c293d46",
   "metadata": {},
   "source": [
    "### Merge the data with JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c0347bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract state names from the GeoJSON file\n",
    "geojson_states = [feature['properties']['name'] for feature in geo_data['features']]\n",
    "\n",
    "# Create a DataFrame from the GeoJSON states\n",
    "geo_df = pd.DataFrame({'State': geojson_states})\n",
    "\n",
    "# Merge the dataset with the GeoJSON DataFrame\n",
    "merged_df = pd.merge(df, geo_df, on='State', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c0c854",
   "metadata": {},
   "source": [
    "## 3. Check for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0696d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States in original dataset but not in merged dataset: set()\n"
     ]
    }
   ],
   "source": [
    "# Check for missing states after merge\n",
    "missing_in_merged = set(df['State']) - set(merged_df['State'])\n",
    "\n",
    "print(f\"States in original dataset but not in merged dataset: {missing_in_merged}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7b54641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data As Of                 0\n",
       "Start Date                 0\n",
       "End Date                   0\n",
       "Year                       0\n",
       "Month                      0\n",
       "State                      0\n",
       "Condition Group            0\n",
       "Condition                  0\n",
       "ICD10_codes                0\n",
       "Age Group                  0\n",
       "COVID-19 Deaths            0\n",
       "Number of Mentions         0\n",
       "Flag                  273574\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62bace8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tjsra\\AppData\\Local\\Temp\\ipykernel_14956\\3541593458.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df['Flag'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values in the 'Flag' column with 0\n",
    "merged_df['Flag'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e77a320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data As Of            0\n",
      "Start Date            0\n",
      "End Date              0\n",
      "Year                  0\n",
      "Month                 0\n",
      "State                 0\n",
      "Condition Group       0\n",
      "Condition             0\n",
      "ICD10_codes           0\n",
      "Age Group             0\n",
      "COVID-19 Deaths       0\n",
      "Number of Mentions    0\n",
      "Flag                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "849919f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Data As Of  Start Date    End Date    Year  Month     State  \\\n",
      "264960  2023-09-24  2020-01-01  2020-01-31  2020.0    1.0  New York   \n",
      "264961  2023-09-24  2020-02-01  2020-02-29  2020.0    2.0  New York   \n",
      "264966  2023-09-24  2020-07-01  2020-07-31  2020.0    7.0  New York   \n",
      "264967  2023-09-24  2020-08-01  2020-08-31  2020.0    8.0  New York   \n",
      "264968  2023-09-24  2020-09-01  2020-09-30  2020.0    9.0  New York   \n",
      "...            ...         ...         ...     ...    ...       ...   \n",
      "273105  2023-09-24  2020-01-01  2020-01-31  2020.0    1.0  New York   \n",
      "273106  2023-09-24  2020-02-01  2020-02-29  2020.0    2.0  New York   \n",
      "273150  2023-09-24  2020-01-01  2020-01-31  2020.0    1.0  New York   \n",
      "273195  2023-09-24  2020-01-01  2020-01-31  2020.0    1.0  New York   \n",
      "273196  2023-09-24  2020-02-01  2020-02-29  2020.0    2.0  New York   \n",
      "\n",
      "             Condition Group                Condition ICD10_codes Age Group  \\\n",
      "264960  Respiratory diseases  Influenza and pneumonia     J09-J18      0-24   \n",
      "264961  Respiratory diseases  Influenza and pneumonia     J09-J18      0-24   \n",
      "264966  Respiratory diseases  Influenza and pneumonia     J09-J18      0-24   \n",
      "264967  Respiratory diseases  Influenza and pneumonia     J09-J18      0-24   \n",
      "264968  Respiratory diseases  Influenza and pneumonia     J09-J18      0-24   \n",
      "...                      ...                      ...         ...       ...   \n",
      "273105              COVID-19                 COVID-19        U071     65-74   \n",
      "273106              COVID-19                 COVID-19        U071     65-74   \n",
      "273150              COVID-19                 COVID-19        U071     75-84   \n",
      "273195              COVID-19                 COVID-19        U071       85+   \n",
      "273196              COVID-19                 COVID-19        U071       85+   \n",
      "\n",
      "        COVID-19 Deaths  Number of Mentions Flag  \n",
      "264960              0.0                 0.0    0  \n",
      "264961              0.0                 0.0    0  \n",
      "264966              0.0                 0.0    0  \n",
      "264967              0.0                 0.0    0  \n",
      "264968              0.0                 0.0    0  \n",
      "...                 ...                 ...  ...  \n",
      "273105              0.0                 0.0    0  \n",
      "273106              0.0                 0.0    0  \n",
      "273150              0.0                 0.0    0  \n",
      "273195              0.0                 0.0    0  \n",
      "273196              0.0                 0.0    0  \n",
      "\n",
      "[2535 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate rows\n",
    "duplicates = merged_df[merged_df.duplicated()]\n",
    "\n",
    "# Print the duplicate rows\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56d81f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows\n",
    "merged_df = merged_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c7098e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows after removal: 0\n"
     ]
    }
   ],
   "source": [
    "# Verify that duplicates are removed\n",
    "print(f\"Number of duplicate rows after removal: {merged_df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c5c6b9",
   "metadata": {},
   "source": [
    "##  4. Plotting a choropleth map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "876ace1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<folium.map.LayerControl at 0x18a722dbbd0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Choropleth map\n",
    "m = folium.Map(location=[37.8, -96.9], zoom_start=4)\n",
    "\n",
    "folium.Choropleth(\n",
    "    geo_data=geo_data,\n",
    "    name='choropleth',\n",
    "    data=merged_df,\n",
    "    columns=['State', 'COVID-19 Deaths'],  # Adjust this to the column you want to visualize\n",
    "    key_on='feature.properties.name',\n",
    "    fill_color='YlOrRd',\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    legend_name='COVID-19 Deaths'\n",
    ").add_to(m)\n",
    "\n",
    "# Add layer control\n",
    "folium.LayerControl().add_to(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30af16e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_path = r\"C:\\Users\\tjsra\\OneDrive\\Desktop\\CF data analyst\\Achievement 6\\04 Analysis\\choropleth_map.html\"\n",
    "m.save(map_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b3ea208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import folium\n",
    "from IPython.display import IFrame\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4de0b88e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"C:\\Users\\tjsra\\OneDrive\\Desktop\\CF data analyst\\Achievement 6\\04 Analysis\\choropleth_map.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x18a70a01090>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the map in the Jupyter Notebook\n",
    "from IPython.display import IFrame\n",
    "IFrame(map_path, width=800, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6cf952b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tjsra\\OneDrive\\Desktop\\CF data analyst\\Achievement 6\\04 Analysis\\choropleth_map.html\n"
     ]
    }
   ],
   "source": [
    "print(map_path)  # Verify the path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9613433",
   "metadata": {},
   "source": [
    "## 5. Answer to Existing Research Questions.\n",
    "\n",
    "###  Which states have the highest and lowest prevalence of COVID-19 deaths?\n",
    "###  The choropleth map clearly shows that California, Florida, and Texas have the highest COVID-19 death rates, indicated by the darkest red color on the map. States like Alaska, Vermont, and Wyoming have the lowest COVID-19 death rates, indicated by the lightest color on the map."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c75ebec",
   "metadata": {},
   "source": [
    "## New Reaearh Questions.\n",
    "\n",
    "###  How does the age distribution in each state affect the COVID-19 death rates?\n",
    "\n",
    "###  What is the role of healthcare infrastructure of each states in COVID-19 death rates?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
